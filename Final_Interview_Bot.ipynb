{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctWOlCy-0sig",
        "outputId": "bf1c86f3-147b-424a-8b23-75be1f49894a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "ngrok.set_auth_token(\"2vDawMr8nxQ2KlLxV7WlpCKBRIw_3se1tn5SGeT7Y2Gv3UUcN\")\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "# Question banks\n",
        "questions = {\n",
        "    \"Data Scientist\": [\n",
        "        \"Can you explain the bias-variance tradeoff?\",\n",
        "        \"What is overfitting and how can you prevent it?\",\n",
        "        \"Describe a project where you used machine learning.\"\n",
        "    ],\n",
        "    \"Frontend Developer\": [\n",
        "        \"What is the virtual DOM?\",\n",
        "        \"Explain the difference between Flexbox and Grid.\",\n",
        "        \"How do you optimize a React application?\"\n",
        "    ],\n",
        "    \"HR\": [\n",
        "        \"Tell me about a time you dealt with a conflict at work.\",\n",
        "        \"How do you handle tight deadlines?\",\n",
        "        \"What motivates you in your job?\"\n",
        "    ],\n",
        "    \"General\": [\n",
        "        \"Why do you want this job?\",\n",
        "        \"How do you work in a team?\",\n",
        "        \"Describe a challenge you overcame.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Session storage\n",
        "sessions = {}\n",
        "\n",
        "def get_mixed_question(role, current_q):\n",
        "    \"\"\"\n",
        "    Alternate questions from role-specific, HR, and General.\n",
        "    e.g., Q0 -> role question, Q1 -> HR question, Q2 -> general question,\n",
        "    Q3 -> next role question, and so on.\n",
        "    \"\"\"\n",
        "    role_qs = questions.get(role, [])\n",
        "    hr_qs = questions[\"HR\"]\n",
        "    gen_qs = questions[\"General\"]\n",
        "\n",
        "    # Calculate index in each category\n",
        "    role_index = current_q // 3\n",
        "    hr_index = current_q // 3\n",
        "    gen_index = current_q // 3\n",
        "\n",
        "    mod = current_q % 3\n",
        "\n",
        "    if mod == 0 and role_index < len(role_qs):\n",
        "        return role_qs[role_index]\n",
        "    elif mod == 1 and hr_index < len(hr_qs):\n",
        "        return hr_qs[hr_index]\n",
        "    elif mod == 2 and gen_index < len(gen_qs):\n",
        "        return gen_qs[gen_index]\n",
        "\n",
        "    # If questions exhausted in a category, fallback to any remaining role questions\n",
        "    remaining_role_qs = role_qs[role_index:] if role_index < len(role_qs) else []\n",
        "    if remaining_role_qs:\n",
        "        return remaining_role_qs[0]\n",
        "\n",
        "    # No more questions\n",
        "    return None\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def home():\n",
        "    return \"âœ… Interview Bot is running! Use POST /start and /answer endpoints.\"\n",
        "\n",
        "@app.route('/start', methods=['POST'])\n",
        "def start_interview():\n",
        "    data = request.json\n",
        "    name = data.get('name')\n",
        "    role = data.get('role')\n",
        "\n",
        "    if not name or not role:\n",
        "        return jsonify({\"error\": \"Please provide 'name' and 'role' in request.\"}), 400\n",
        "\n",
        "    if role not in questions:\n",
        "        # Clarifying question if role not supported\n",
        "        return jsonify({\n",
        "            \"error\": \"Role not supported.\",\n",
        "            \"message\": \"Can you specify your role or skill set more precisely?\"\n",
        "        }), 400\n",
        "\n",
        "    session_id = f\"{name}_{role}\"\n",
        "    sessions[session_id] = {\n",
        "        \"name\": name,\n",
        "        \"role\": role,\n",
        "        \"current_q\": 0,\n",
        "        \"answers\": []\n",
        "    }\n",
        "    first_question = get_mixed_question(role, 0)\n",
        "    return jsonify({\"question\": first_question, \"session_id\": session_id})\n",
        "\n",
        "@app.route('/answer', methods=['POST'])\n",
        "def answer_question():\n",
        "    data = request.json\n",
        "    session_id = data.get('session_id')\n",
        "    answer = data.get('answer')\n",
        "\n",
        "    if not session_id or not answer:\n",
        "        return jsonify({\"error\": \"Please provide 'session_id' and 'answer'.\"}), 400\n",
        "\n",
        "    if session_id not in sessions:\n",
        "        return jsonify({\"error\": \"Session not found.\"}), 404\n",
        "\n",
        "    session = sessions[session_id]\n",
        "    session['answers'].append(answer)\n",
        "    session['current_q'] += 1\n",
        "\n",
        "    next_q = get_mixed_question(session['role'], session['current_q'])\n",
        "\n",
        "    if not next_q:\n",
        "        return jsonify({\n",
        "            \"message\": \"Interview completed\",\n",
        "            \"answers\": session['answers']\n",
        "        })\n",
        "\n",
        "    return jsonify({\"question\": next_q})\n",
        "\n",
        "def run_app():\n",
        "    app.run(port=5000)\n",
        "\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X30ymzRG5Mbf",
        "outputId": "23a8b291-7773-41bc-848e-93d1b9692eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://2a69-35-184-44-178.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "ngrok_url = \"https://1708-35-184-44-178.ngrok-free.app\"  # Replace with your actual ngrok URL\n",
        "\n",
        "# Start interview by asking for candidate name and role\n",
        "name = input(\"Enter your name: \")\n",
        "role = input(\"Enter the role you are applying for: \")\n",
        "\n",
        "start_resp = requests.post(f\"{ngrok_url}/start\", json={\n",
        "    \"name\": name,\n",
        "    \"role\": role\n",
        "})\n",
        "\n",
        "if start_resp.status_code != 200:\n",
        "    print(\"Error:\", start_resp.json().get(\"error\"))\n",
        "    exit()\n",
        "\n",
        "data = start_resp.json()\n",
        "print(\"\\nQuestion 1:\", data[\"question\"])\n",
        "\n",
        "session_id = data[\"session_id\"]\n",
        "question_num = 1\n",
        "\n",
        "while True:\n",
        "    answer = input(\"Your answer: \")\n",
        "    answer_resp = requests.post(f\"{ngrok_url}/answer\", json={\n",
        "        \"session_id\": session_id,\n",
        "        \"answer\": answer\n",
        "    })\n",
        "\n",
        "    if answer_resp.status_code != 200:\n",
        "        print(\"Error:\", answer_resp.json().get(\"error\"))\n",
        "        break\n",
        "\n",
        "    data = answer_resp.json()\n",
        "    if \"message\" in data and data[\"message\"] == \"Interview completed\":\n",
        "        print(\"\\nInterview Completed! Your answers:\")\n",
        "        for i, ans in enumerate(data[\"answers\"], 1):\n",
        "            print(f\"{i}. {ans}\")\n",
        "        print(\"\\nThank you for your time! We will get back to you soon. Goodbye! ðŸ‘‹\")\n",
        "        break\n",
        "    else:\n",
        "        question_num += 1\n",
        "        print(f\"\\nQuestion {question_num}:\", data[\"question\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D6mfOwb-RbT",
        "outputId": "83d11df8-430b-4396-edc0-f19145dcb97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your name: Iram Fatima\n",
            "Enter the role you are applying for: Data Scientist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/May/2025 12:38:32] \"POST /start HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question 1: Can you explain the bias-variance tradeoff?\n",
            "Your answer: I don't know\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/May/2025 12:38:39] \"POST /answer HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question 2: Tell me about a time you dealt with a conflict at work.\n",
            "Your answer: When I was a secretary and had to organize  tech fest I had to dela with the conflict between president and vice president\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/May/2025 12:39:51] \"POST /answer HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question 3: Why do you want this job?\n",
            "Your answer: because I have a great understanding about data science and is a perfect candidate for this role\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/May/2025 12:40:46] \"POST /answer HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question 4: What is overfitting and how can you prevent it?\n",
            "Your answer: I don't know\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/May/2025 12:40:55] \"POST /answer HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question 5: How do you handle tight deadlines?\n",
            "Your answer: working\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/May/2025 12:41:01] \"POST /answer HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question 6: How do you work in a team?\n",
            "Your answer: By agreeing with everyone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/May/2025 12:42:58] \"POST /answer HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question 7: Describe a project where you used machine learning.\n",
            "Your answer: surprise housing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/May/2025 12:43:04] \"POST /answer HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question 8: What motivates you in your job?\n",
            "Your answer: curiosity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/May/2025 12:43:11] \"POST /answer HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question 9: Describe a challenge you overcame.\n",
            "Your answer: my fear of public speaking\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/May/2025 12:43:22] \"POST /answer HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Interview Completed! Your answers:\n",
            "1. I don't know\n",
            "2. When I was a secretary and had to organize  tech fest I had to dela with the conflict between president and vice president\n",
            "3. because I have a great understanding about data science and is a perfect candidate for this role\n",
            "4. I don't know\n",
            "5. working\n",
            "6. By agreeing with everyone\n",
            "7. surprise housing\n",
            "8. curiosity\n",
            "9. my fear of public speaking\n",
            "\n",
            "Thank you for your time! We will get back to you soon. Goodbye! ðŸ‘‹\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gDTYDKRfJ0oc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}